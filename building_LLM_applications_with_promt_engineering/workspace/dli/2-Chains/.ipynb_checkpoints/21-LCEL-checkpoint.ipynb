{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc270c33",
   "metadata": {},
   "source": [
    "<center><a href=\"https://www.nvidia.cn/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d556ad",
   "metadata": {},
   "source": [
    "# LangChain 表达语言和链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from videos.walkthroughs import walkthrough_21 as walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3bf394",
   "metadata": {},
   "outputs": [],
   "source": [
    "walkthrough()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f57f6f8",
   "metadata": {},
   "source": [
    "在这个 notebook 中，您将学习 LangChain 运行时，以及如何使用 LangChain 表达语言（LCEL）将它们组合成链。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4838a170",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fe7be9",
   "metadata": {},
   "source": [
    "## 目标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e55f5c2",
   "metadata": {},
   "source": [
    "完成这个 notebook 后，您将：\n",
    "\n",
    "- 理解 LangChain 运行时作为 LangChain 中的工作单元。\n",
    "- 使用 LLM 实例和提示模板作为运行时。\n",
    "- 创建和使用可运行的输出解析器（parser）。\n",
    "- 使用 LCEL 管道语法（pipe syntax）将运行时组合成 LangChain 链。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9600ae00",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ee7be4",
   "metadata": {},
   "source": [
    "## 导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee2b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d556e2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d6abb",
   "metadata": {},
   "source": [
    "## 创建模型实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fbb9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://llama:8000/v1'\n",
    "model = 'meta/llama-3.1-8b-instruct'\n",
    "llm = ChatNVIDIA(base_url=base_url, model=model, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1593377d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4973c2d",
   "metadata": {},
   "source": [
    "## LangChain 运行时"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287533c8",
   "metadata": {},
   "source": [
    "在之前的 notebook 中，您学习了如何创建简单的 LangChain 提示模板，并通过 `invoke` 方法用特定值实例化它们的模板占位符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e85a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_template(\"Answer the following question: {question}\")\n",
    "prompt = template.invoke({\"question\": \"In what city is NVIDIA world headquarters?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00875db3",
   "metadata": {},
   "source": [
    "您还知道，当将提示发送给我们在 LangChain 中创建的 LLM 实例（在我们的例子中是 LangChain 组件 `ChatNVIDIA`）时，我们使用模型实例的 `invoke` 方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e51460",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1451ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c0d66",
   "metadata": {},
   "source": [
    "在 LLM 实例和提示模板上都有 `invoke` 方法并不是巧合，它们都是 LangChain 的**运行时（runnable）**。\n",
    "\n",
    "在 LangChain 中，**运行时**是可以被调用的工作单元（就像我们调用 LLM 实例和提示模板），可以进行批处理和流式处理，也可以进行转换和组合（这部分我们还没做）。\n",
    "\n",
    "为了验证这一点，我们来试试 `batch` 方法，这是我们在 LLM 实例上使用过的，但还没在提示模板上使用。因为提示模板也是运行时，就像 LLM 实例一样，运行时也可以批处理，所以以下代码应该可以正常工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cd1aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    {\"question\": \"In what city is NVIDIA world headquarters?\"},\n",
    "    {\"question\": \"When was NVIDIA founded?\"},\n",
    "    {\"question\": \"Who is the CEO of NVIDIA?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b15170",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = template.batch(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12585a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811c081c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d150c9ae",
   "metadata": {},
   "source": [
    "## LangChain 表达语言（LCEL）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa3c448",
   "metadata": {},
   "source": [
    "LCEL 用一种声明式的方法将运行时组合成**链**：可复用的功能组合。我们通过 LCEL 的管道 `|` 操作符将运行时链接在一起，从高层次来看，就是将一个运行时的输出传递给下一个。\n",
    "\n",
    "对于那些使用过 Unix 命令行的朋友来说，您会熟悉 `|` 操作符，它是将各种程序的功能链接在一起以服务于整体任务的一种方式。\n",
    "\n",
    "如果您对 Bash 不是很了解，不用太担心下面的单元。但对于了解的朋友，您会看到我们通过管道操作符创建了一个链，用 `echo` 打印“hello pipes”，用 `rev` 反转字符串，然后用 `tr` 转为大写。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo hello pipes | rev | tr 'a-z' 'A-Z'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e790069",
   "metadata": {},
   "source": [
    "同样，我们也可以用 LCEL 的管道操作符将许多 LangChain 的功能方便地链接在一起。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8cae18",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f901f",
   "metadata": {},
   "source": [
    "## 一个简单的链"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25c7b0c",
   "metadata": {},
   "source": [
    "让我们从一个简单的链开始，这与您之前的工作相关。为了方便查看，我们将再次在这里定义 LLM 实例和一个提示模板。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatNVIDIA(base_url=base_url, model=model, temperature=0)\n",
    "template = ChatPromptTemplate.from_template(\"Answer the following question: {question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360248b",
   "metadata": {},
   "source": [
    "现在我们将通过管道将这两个组合在一起，创建我们的第一个 LCEL 链。一般来说，应该先经过提示模板，然后将生成的提示词发送给 LLM，因此我们将在管道中先放置模板。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd887e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba0b433",
   "metadata": {},
   "source": [
    "可以使用链的辅助方法来可视化由 `chain` 表示的计算图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6593e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7b869",
   "metadata": {},
   "source": [
    "如您所见，链将期待一个 `PromptInput`，这个输入将被传递到 `ChatPromptTemplate` 中，然后再传递到 `ChatNVIDIA` 模型，最终生成 `ChatNVIDIAOutput`。\n",
    "\n",
    "此外，我们还可以规定链所期望的输入类型，这次使用一个不同的辅助方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f465fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9b6a6f",
   "metadata": {},
   "source": [
    "上面是一个 [Pydantic](https://docs.pydantic.dev/latest/) 对象，我们现在不会深入探讨，但您会立即注意到它的 `required` 字段明确指出了我们需要传递给 `chain` 的任何属性名称。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1c0dbd",
   "metadata": {},
   "source": [
    "链是由运行时组成的，但它们自己也是运行时。因此，就像我们对待任何其它运行时一样，可以使用其 `invoke` 方法。\n",
    "\n",
    "我们知道链的开始部分需要一个提示输入，而提示模板希望我们为 `question` 提供一个值，因此我们将在调用链时提供预期的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d02fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": \"Who founded NVIDIA?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eb7824",
   "metadata": {},
   "source": [
    "看起来我们收到了来自模型的消息，就像在直接调用模型实例时一样。保存这个响应，看看能否像之前那样查看其 `content` 字段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d024174",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = chain.invoke({\"question\": \"Who founded NVIDIA?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece29f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012fd983",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2aacf6",
   "metadata": {},
   "source": [
    "## 输出解析器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481c20d0",
   "metadata": {},
   "source": [
    "另一个核心的 LangChain 组件是**输出解析器**，它是用于帮助结构化 LLM 响应的类。输出解析器和 LLM 实例以及提示模板一样，都是运行时，这意味着我们可以在链中使用它们。\n",
    "\n",
    "让我们从最简单的输出解析器 `StrOutputParser` 开始，它将为我们节省所有重复的代码，不再需要从模型响应中提取 `content` 字段。\n",
    "\n",
    "首先我们导入 `StrOutputParser` 类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bde2b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be2827b",
   "metadata": {},
   "source": [
    "接下来我们创建解析器的一个实例。对于一些更高级的解析技术（我们稍后会看到），可以用各种参数来实例化解析器，但对于当前这个简单的解析器，我们在实例化时不需要传入任何参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f851510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c319417",
   "metadata": {},
   "source": [
    "之前看到的所有运行时都有 `invoke`、`batch` 和 `stream` 方法，我们可以预期在 `parser` 上也能调用这些方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f2e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.invoke('parse this string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a068fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.batch(['parse this string', 'and this string too'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7a7ef1",
   "metadata": {},
   "source": [
    "此外，也是最重要的，我们还希望能够在链中使用 `parser`。让我们重新创建之前的链，但通过将模型输出传递给输出解析器来扩展它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba5cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007cb93f",
   "metadata": {},
   "source": [
    "这里可以再次使用链的辅助方法来可视化由 `chain` 表示的计算图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4359b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c386349",
   "metadata": {},
   "source": [
    "现在让我们调用这个链，并传入预期的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06153709",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": \"Who invented the use of the pipe symbol in Unix systems?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca78e1f",
   "metadata": {},
   "source": [
    "或许您会同意，像这样声明式地创建链，跟之前的方法相比是一个巨大的改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d2a8f0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d18659",
   "metadata": {},
   "source": [
    "## 练习：重新实现翻译"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f46759",
   "metadata": {},
   "source": [
    "创建一个能够翻译给定语句、源语言和目标语言的链。\n",
    "\n",
    "如果您遇到困难，请查看下面的*参考答案*。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da236464",
   "metadata": {},
   "source": [
    "### 您的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab8f4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01d29806",
   "metadata": {},
   "source": [
    "### 参考答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd92ea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_template = ChatPromptTemplate.from_template(\"\"\"Translate the following statement from {from_language} to {to_language}. \\\n",
    "Provide only the translated text: {statement}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac29896",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_chain = translate_template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e51cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(translation_chain.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2920d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ee86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_chain.invoke({\n",
    "    \"from_language\": \"English\",\n",
    "    \"to_language\": \"German\",\n",
    "    \"statement\": \"No matter who you are it's fun to learn new things.\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aaccb3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1051b4",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcc9a2c",
   "metadata": {},
   "source": [
    "在这个 notebook 中，您学习了如何使用运行时，特别是 3 个核心的 LangChain 运行时：LLM 实例、提示模板和输出解析器。\n",
    "\n",
    "下一个 notebook 将继续关注创建和组合运行时，并引入创建自定义运行时的能力。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

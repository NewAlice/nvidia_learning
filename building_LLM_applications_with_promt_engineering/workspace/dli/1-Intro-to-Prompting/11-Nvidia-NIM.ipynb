{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a06cb2e",
   "metadata": {},
   "source": [
    "<center><a href=\"https://www.nvidia.cn/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815cdbfe",
   "metadata": {},
   "source": [
    "# NVIDIA NIM 用于提示工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c2303f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from videos.walkthrough import walkthrough_11 as walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc004b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "walkthrough()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e4ba2",
   "metadata": {},
   "source": [
    "## 目标\n",
    "\n",
    "完成这个 notebook 后，您将能够：\n",
    "\n",
    "- 了解我们将如何利用 NVIDIA 推理微服务进行提示工程\n",
    "- 介绍本地托管大语言模型相比于 API 托管 LLM 的好处"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4ee298",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8650f866",
   "metadata": {},
   "source": [
    "## NVIDIA 推理微服务（NVIDIA Inference Microservice）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5ff842",
   "metadata": {},
   "source": [
    "NVIDIA NIM 是一组易于使用的微服务，旨在安全、可靠地部署高性能 AI 模型推理，适用于云端、数据中心和工作站。它支持很多 AI 模型，包括开源社区和 NVIDIA AI Foundation 模型，确保在本地或云端无缝、可扩展地遵循行业标准 API 进行 AI 推理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923a1e36",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c415e063",
   "metadata": {},
   "source": [
    "## build.nvidia.com\n",
    "\n",
    "您可以快速浏览 [build.nvidia.com](https://build.nvidia.com/explore/discover) 上可用的模型，比如开源 LLM [Llama3.1-405b](https://build.nvidia.com/meta/llama-3_1-405b-instruct) 和图像生成模型 [Stable-diffusion-xl](https://build.nvidia.com/explore/visual-design#stable-diffusion-xl)。\n",
    "\n",
    "在这个网站上，您还可以通过图形界面预览模型表现。\n",
    "\n",
    "![build.nvidia.com](images/build.nvidia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04dd54",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5582dd",
   "metadata": {},
   "source": [
    "## API 托管的 NIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3e616",
   "metadata": {},
   "source": [
    "您还可以通过 [build.nvidia.com](https://build.nvidia.com/explore/discover) 和一个 `nvapi` 密钥，以编程方式与 API 托管的 NIM 微服务互动。\n",
    "\n",
    "使用 build.nvidia.com API 目录（API catalog）是实验 NIM 微服务的好方法。一旦您确定了一个感兴趣的模型，就可以将 NIM 下载到本地，继续进行完整的应用开发。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b986ab07",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad8ebd",
   "metadata": {},
   "source": [
    "## 课程环境"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de17884",
   "metadata": {},
   "source": [
    "当您首次启动这个课程时，深度学习培训中心（DLI）会为您分配一个云平台实例。\n",
    "借助这个云实例，我们部署了一系列用户、系统可依赖的微服务。\n",
    "这一系列通过 Docker 部署的微服务，囊括了当前的 Jupyter Lab 环境和 NIM 容器。\n",
    "\n",
    "NIM 微服务是按模型/模型家族打包为容器镜像的。在这个课程环境中，我们下载了包含 [meta/llama-3_1-8b-Instruct](https://build.nvidia.com/explore/discover#llama-3_1-8b-instruct) 模型的 NIM 容器。\n",
    "\n",
    "这个容器包含一个在具备足够内存的 NVIDIA GPU 上运行的运行时。NIM 微服务会自动从 NGC（企业服务、软件、管理工具和支持端到端 AI 工作流的门户）下载模型，并在可用时通过本地文件系统进行缓存。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27209a9f",
   "metadata": {},
   "source": [
    "![NIMDeploymentLifecycle](images/NIM_Deployment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf55c1b",
   "metadata": {},
   "source": [
    "LLM NIM 微服务有很多好处，这里简单提几条。\n",
    "\n",
    "- **速度**：LLM NIM 微服务支持针对多种前沿 LLM 架构预生成的优化引擎，降低推理延迟。\n",
    "- **可扩展部署**：API 托管的 LLM 在大规模或高流量需求下可能成本高昂，而本地部署提供了更具性价比的解决方案。通过在初始设置上进行一些投入，您可以轻松通过增加计算资源或将模型分布在多台机器上来扩展本地托管的模型。\n",
    "- **所有权**：一旦设置完成，本地运行模型使您拥有自定义和完全控制知识产权及 AI 应用的权利。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d2594c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c277954",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676929ae",
   "metadata": {},
   "source": [
    "在这个 notebook 中，您了解了 NVIDIA NIM 微服务，并学习了多种使用它们的方法。现在您知道 NIM 是什么了，下面进入下一个 notebook，您将开始与本地运行的 Llama-3.1 8b instruct NIM 进行交互。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c75681e6",
   "metadata": {},
   "source": [
    "<center><a href=\"https://www.nvidia.cn/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c77ecc6",
   "metadata": {},
   "source": [
    "# 聊天机器人（Chatbot）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e40ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from videos.walkthroughs import walkthrough_35 as walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d035529",
   "metadata": {},
   "outputs": [],
   "source": [
    "walkthrough()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94356bf",
   "metadata": {},
   "source": [
    "在这个 notebook 中，您将学习如何存储对话历史，从而在基于 LLM 的链中启用聊天机器人功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de462755",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d533be38",
   "metadata": {},
   "source": [
    "## 目标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0502c5",
   "metadata": {},
   "source": [
    "当您完成这个 notebook 时，您将会：\n",
    "\n",
    "- 理解创建能保留对话历史的聊天机器人应用所需的核心原理和技术。\n",
    "- 创建易于使用的聊天机器人，能够扮演多种不同的角色。\n",
    "- 与一个简单的聊天机器人应用界面进行交互。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e29ab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9adea5",
   "metadata": {},
   "source": [
    "## 导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a9a97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86726ba3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4145d89a",
   "metadata": {},
   "source": [
    "## 创建模型实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbf9226",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://llama:8000/v1'\n",
    "model = 'meta/llama-3.1-8b-instruct'\n",
    "llm = ChatNVIDIA(base_url=base_url, model=model, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf943a87",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4df92bf",
   "metadata": {},
   "source": [
    "## 占位符消息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a49fde2",
   "metadata": {},
   "source": [
    "在启用对话历史和聊天机器人功能之前，我们需要介绍一种尚未讲过的新类型消息，**占位符（placeholder）**消息。\n",
    "\n",
    "简单来说，占位符消息用于在提示词模板中占据其它消息列表的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23cc2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_with_placeholder = ChatPromptTemplate.from_messages([\n",
    "    ('placeholder', '{messages}'),\n",
    "    ('human', '{prompt}')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0752ef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ('human', 'The sun came up today.'),\n",
    "    ('ai', 'That is wonderful!'),\n",
    "    ('human', 'The sun went down today.'),\n",
    "    ('ai', 'That is also wonderful!.')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54a4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'What happened today?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6748b32",
   "metadata": {},
   "source": [
    "在调用（或流式处理或批处理）包含占位符消息的提示模板或链时，我们提供一个模板所需的值。而有占位符消息的话，则提供一组其它消息，而非一个字符串。\n",
    "\n",
    "这里我们调用 `template_with_placeholder`，传入 `messages` 列表以满足模板的 `messages` 参数，并传入 `prompt` 字符串以满足 `prompt` 参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15545493",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_with_placeholder.invoke({'messages': messages, 'prompt': prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37393e94",
   "metadata": {},
   "source": [
    "正如您所看到的，LangChain 扩展了我们提供的消息列表，形成了在调用提示模板时提供的单个消息列表。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeeb7a8",
   "metadata": {},
   "source": [
    "我们可以像使用其它任何模板一样在链中使用这个提示模板。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3dcee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template_with_placeholder | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1da96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({'messages': messages, 'prompt': prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce8494",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4274509f",
   "metadata": {},
   "source": [
    "## 基本对话历史"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c79deb",
   "metadata": {},
   "source": [
    "我们可以用消息占位符轻松地构建一个基本的对话历史机制。首先，创建一个利用占位符的提示模板，并在一个简单的链中使用它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b95ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_conversation_template = ChatPromptTemplate.from_messages([\n",
    "    ('placeholder', '{chat_conversation}')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1cf1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_chain = chat_conversation_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bf0c40",
   "metadata": {},
   "source": [
    "接下来，创建一个列表储存对话，随着时间的推移，它会不断添加内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b4054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_conversation = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb55a1",
   "metadata": {},
   "source": [
    "首先将添加第一个 `user` 消息到 `chat_conversation` 列表中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b0ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_conversation.append(('user', 'Hello, my name is Michael.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a1af5",
   "metadata": {},
   "source": [
    "测试一下，现在可以用当前的 `chat_conversation` 列表调用我们的 `chat_chain`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a670bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_chain.invoke({'chat_conversation': chat_conversation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4b6a7",
   "metadata": {},
   "source": [
    "看起来 LLM 能够很好地回应。不过，由于我们想要保持对话历史，再调用一次链，这次将响应作为 `ai` 消息添加到 `chat_conversation` 列表中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4031eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_chain.invoke({'chat_conversation': chat_conversation})\n",
    "chat_conversation.append(('ai', response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcd118d",
   "metadata": {},
   "source": [
    "查看 `chat_conversation`，我们看到它现在包含了迄今为止的消息列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9846fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dab64b",
   "metadata": {},
   "source": [
    "让我们用一条新消息重复这个过程，传入一个依赖于之前对话历史的提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e56ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_conversation.append(('user', 'Do you remember what my name is?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e38ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_chain.invoke({'chat_conversation': chat_conversation})\n",
    "chat_conversation.append(('ai', response))\n",
    "chat_conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a720695b",
   "metadata": {},
   "source": [
    "正如您所看到的，通过将用户提示和 AI 响应分别作为 `user` 和 `ai` 消息附加到 `chat_conversation` 中，然后用整个更新后的对话调用包含占位符的 `chat_chain`，就能与 LLM 进行保留之前对话细节的对话。\n",
    "\n",
    "基本上，所有能保留对话历史的聊天机器人功能，都是利用这种在新用户消息之前传递对话历史的方式实现的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e2664",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bff775",
   "metadata": {},
   "source": [
    "## 聊天机器人类（Chatbot Class）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53241a9e",
   "metadata": {},
   "source": [
    "我们可以将上面实现的功能封装到一个类中，这样与支持对话历史的 LLM 交互就会简单很多。请仔细阅读以下 `Chatbot` 类的定义，包括注释。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7f6712",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self, llm):\n",
    "        # This is the same prompt template we used earlier, which a placeholder message for storing conversation history.\n",
    "        chat_conversation_template = ChatPromptTemplate.from_messages([\n",
    "            ('placeholder', '{chat_conversation}')\n",
    "        ])\n",
    "\n",
    "        # This is the same chain we created above, added to `self` for use by the `chat` method below.\n",
    "        self.chat_chain = chat_conversation_template | llm | StrOutputParser()\n",
    "\n",
    "        # Here we instantiate an empty list that will be added to over time.\n",
    "        self.chat_conversation = []\n",
    "\n",
    "    # `chat` expects a simple string prompt.\n",
    "    def chat(self, prompt):\n",
    "        # Append the prompt as a user message to chat conversation.\n",
    "        self.chat_conversation.append(('user', prompt))\n",
    "        \n",
    "        response = self.chat_chain.invoke({'chat_conversation': self.chat_conversation})\n",
    "        # Append the chain response as an `ai` message to chat conversation.\n",
    "        self.chat_conversation.append(('ai', response))\n",
    "        # Return the chain response to the user for viewing.\n",
    "        return response\n",
    "\n",
    "    # Clear conversation history.\n",
    "    def clear(self):\n",
    "        self.chat_conversation = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa66f8fe",
   "metadata": {},
   "source": [
    "让我们实例化一个聊天机器人实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea8cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = Chatbot(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d23cc04",
   "metadata": {},
   "source": [
    "现在可以调用 `chat` 方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1134de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chatbot.chat('Hi, my name is Michael.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chatbot.chat('I just want to be reminded of my name please.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f9092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chatbot.chat(\"Tell me something interesting I probably don't know about pi.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dfed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chatbot.chat(\"That's really cool! Give me another.\")) # Note we are not being specific about what \"another\" refers to...the LLM needs to have previous messages to understand our intent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e82ce",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc873e",
   "metadata": {},
   "source": [
    "## 更高级的聊天机器人"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef760ba",
   "metadata": {},
   "source": [
    "管理对话历史和创建聊天机器人都是相当广泛的话题，还有很多更高级的技术超出了本次课程的范围。不过，我们还是想为您提供一些额外的参考资料，以便进一步研究这个话题。\n",
    "\n",
    "- [基于会话的对话历史修剪](https://python.langchain.com/docs/how_to/chatbots_memory/): LangChain 提供了一种提供历史管理能力的链封装方式，在需要管理多个会话时尤其有帮助。这一资料介绍了使用 LangChain 工具管理基于会话的对话历史，并涵盖了一些通过消息修剪和摘要来管理对话历史长度的技术，这是一个重要的话题，因为聊天对话可能会变得很长，甚至大到无法继续传给 LLM。\n",
    "- [对话式 RAG](https://python.langchain.com/docs/tutorials/qa_chat_history/): 检索增强生成（Retrieval Augmented Generation，简称 RAG）（更多信息见[这个深度学习培训中心（DLI）的自学课程](https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+S-FX-15+V1-ZH)）是一种让 LLM 可以实时从外部数据源获取上下文，以生成响应的技术。这一资料讨论了如何在保留对话历史的聊天机器人中使用 RAG。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81d3717",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea927074",
   "metadata": {},
   "source": [
    "## 练习：基于角色的聊天机器人"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc1099",
   "metadata": {},
   "source": [
    "在这个练习中，您将利用系统消息，使聊天机器人实例能够担任特定角色。\n",
    "\n",
    "下面是 `ChatbotWithRole` 的类定义，现在与上面的 `Chatbot` 类定义完全相同，只是多了一个 `system_message` 参数（默认为空字符串），在实例化 `ChatbotWithRole` 实例时可以用它。\n",
    "\n",
    "根据需要编辑类定义，以便您可以提供一个系统消息，为您的聊天机器人创建一个特定角色。完成后，您应该能够使用如下的系统消息为您的聊天机器人创建一个总体角色。\n",
    "\n",
    "如果您卡住了，欢迎查看下面的*参考答案*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed9bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_chatbot_system_message = \"You always answer as briefly and concisely as possible.\"\n",
    "\n",
    "curious_chatbot_system_message = \"\"\"\\\n",
    "You are incredibly curious, and often respond with reflections and followup questions that lean the conversation in the direction of playfully \\\n",
    "understanding more about the subject matters of the conversation.\"\"\"\n",
    "\n",
    "increased_vocabulary_system_message = \"\"\"\\\n",
    "You always respond using challenging and often under-utilized vocabulary words, even when your response could be made more simply.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f4e1d4",
   "metadata": {},
   "source": [
    "### 您的代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee125660",
   "metadata": {},
   "source": [
    "更新以下类定义，以便传入的 `system_message` 能有效地被聊天机器人实例使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6015d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotWithRole:\n",
    "    def __init__(self, llm, system_message=''):\n",
    "        # This is the same prompt template we used earlier, which a placeholder message for storing conversation history.\n",
    "        chat_conversation_template = ChatPromptTemplate.from_messages([\n",
    "            ('placeholder', '{chat_conversation}')\n",
    "        ])\n",
    "\n",
    "        # This is the same chain we created above, added to `self` for use by the `chat` method below.\n",
    "        self.chat_chain = chat_conversation_template | llm | StrOutputParser()\n",
    "\n",
    "        # Here we instantiate an empty list that will be added to over time.\n",
    "        self.chat_conversation = []\n",
    "\n",
    "    # `chat` expects a simple string prompt.\n",
    "    def chat(self, prompt):\n",
    "        # Append the prompt as a user message to chat conversation.\n",
    "        self.chat_conversation.append(('user', prompt))\n",
    "        \n",
    "        response = self.chat_chain.invoke({'chat_conversation': self.chat_conversation})\n",
    "        # Append the chain response as an `ai` message to chat conversation.\n",
    "        self.chat_conversation.append(('ai', response))\n",
    "        # Return the chain response to the user for viewing.\n",
    "        return response\n",
    "\n",
    "    # Clear conversation history.\n",
    "    def clear(self):\n",
    "        self.chat_conversation = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a927e067",
   "metadata": {},
   "source": [
    "### 试一个带角色的聊天机器人"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd84823a",
   "metadata": {},
   "source": [
    "在成功实现 `ChatbotWithRole` 后，尝试用您选择的系统消息创建一个实例并与之交互。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e45733c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34ba2044",
   "metadata": {},
   "source": [
    "### 参考答案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fb7163",
   "metadata": {},
   "source": [
    "这里，我们向 `chat_conversation_template` 添加了一个额外的系统消息，该消息使用了传入的 `system_message`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f8533",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotWithRole:\n",
    "    def __init__(self, llm, system_message=''):\n",
    "        # This is the same prompt template we used earlier, which a placeholder message for storing conversation history.\n",
    "        chat_conversation_template = ChatPromptTemplate.from_messages([\n",
    "            ('system', system_message),\n",
    "            ('placeholder', '{chat_conversation}')\n",
    "        ])\n",
    "\n",
    "        # This is the same chain we created above, added to `self` for use by the `chat` method below.\n",
    "        self.chat_chain = chat_conversation_template | llm | StrOutputParser()\n",
    "\n",
    "        # Here we instantiate an empty list that will be added to over time.\n",
    "        self.chat_conversation = []\n",
    "\n",
    "    # `chat` expects a simple string prompt.\n",
    "    def chat(self, prompt):\n",
    "        # Append the prompt as a user message to chat conversation.\n",
    "        self.chat_conversation.append(('user', prompt))\n",
    "        \n",
    "        response = self.chat_chain.invoke({'chat_conversation': self.chat_conversation})\n",
    "        # Append the chain response as an `ai` message to chat conversation.\n",
    "        self.chat_conversation.append(('ai', response))\n",
    "        # Return the chain response to the user for viewing.\n",
    "        return response\n",
    "\n",
    "    # Clear conversation history.\n",
    "    def clear(self):\n",
    "        self.chat_conversation = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21b055c",
   "metadata": {},
   "source": [
    "试一个上面定义的系统消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f456eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_chatbot = ChatbotWithRole(llm, system_message=brief_chatbot_system_message)\n",
    "curious_chatbot = ChatbotWithRole(llm, system_message=curious_chatbot_system_message)\n",
    "increased_vocabulary_chatbot = ChatbotWithRole(llm, system_message=increased_vocabulary_system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d6ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(brief_chatbot.chat(\"What would you consider a good morning routine?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c977959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(curious_chatbot.chat(\"What would you consider a good morning routine?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40053549",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(increased_vocabulary_chatbot.chat(\"What would you consider a good morning routine?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97004dde",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e88af",
   "metadata": {},
   "source": [
    "## Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4743319e",
   "metadata": {},
   "source": [
    "_“Gradio 是展示您的机器学习模型最快的方法，它提供了一个友好的 web 界面，任何人都可以在任何地方使用！”_\n",
    "\n",
    "如果您正在构建聊天机器人，尤其是为创建原型或供个人使用的聊天机器人，可以试试 [Gradio](https://www.gradio.app/)，它可以在 Jupyter 环境中简单地创建出一个聊天界面。\n",
    "\n",
    "将一个 `chatbot` 实例（可以通过 `Chatbot` 类或 `ChatbotWithRole` 类创建）传入以下 `create_chatbot_interface` 函数，就可以开始对话了。如果您感兴趣，可以看看 [chat_helpers/gradio_interface.py](chat_helpers/gradio_interface.py) 的源代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7349d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chat_helpers.gradio_interface import create_chatbot_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680bf7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = create_chatbot_interface(curious_chatbot)\n",
    "app.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f0b1f9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e495b9e",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e2b9b",
   "metadata": {},
   "source": [
    "在这个 notebook 中，您学习了如何利用一种新的消息类型，即占位符消息，来创建能够保留对话历史的聊天机器人。\n",
    "\n",
    "这是本节的最后一个 notebook，旨在使用聊天消息类型来提升 LLM 应用的效果。除了管理对话历史外，您还学习了许多技术，包括少样本提示、使用系统消息及执行思维链提示。\n",
    "\n",
    "在接下来的部分中，您将专注于使用多种提示工程技术，使您的基于 LLM 的应用能生成结构化数据，这是一种强大的能力，可以让您的 LLM 应用更及时地与下游代码交互，并为借助 LLM 标记（tag）和分析大量文本数据打开了无限可能。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

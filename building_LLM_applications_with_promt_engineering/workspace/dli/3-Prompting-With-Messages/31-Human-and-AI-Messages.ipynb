{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc97c5e",
   "metadata": {},
   "source": [
    "<center><a href=\"https://www.nvidia.cn/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f472ebe",
   "metadata": {},
   "source": [
    "# 人类与 AI 消息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786df683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from videos.walkthroughs import walkthrough_31 as walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c662b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "walkthrough()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6530a5",
   "metadata": {},
   "source": [
    "在这个 notebook 中，您将了解两种核心聊天消息类型，人类消息和 AI 消息，以及如何在应用代码中明确使用它们。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b053c647",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928da524",
   "metadata": {},
   "source": [
    "## 目标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e7cb8",
   "metadata": {},
   "source": [
    "在您完成这个 notebook 时，您将会：\n",
    "\n",
    "- 明确聊天变体 LLM 所使用的基于角色的消息传递系统。\n",
    "- 学会如何使用 `ChatPromptTemplate` 在提示模板中创建人类和AI 消息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b85e4bd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba59ef5",
   "metadata": {},
   "source": [
    "## 导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb44a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02764545",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1039f4b7",
   "metadata": {},
   "source": [
    "## 创建模型实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b027f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://llama:8000/v1'\n",
    "model = 'meta/llama-3.1-8b-instruct'\n",
    "llm = ChatNVIDIA(base_url=base_url, model=model, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c25bb3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fa23dc",
   "metadata": {},
   "source": [
    "## 聊天消息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0481b52",
   "metadata": {},
   "source": [
    "正如我们在课程中之前提到的，与“聊天”或“指令”类型的 LLM 工作时有一些重要的区别，而非聊天模型主要是用来生成接下来应该出现的文本。\n",
    "\n",
    "我们在整个课程中一直在用 LangChain 构建提示词，主要是通过 `ChatPromptTemplate`。如名称中的“聊天”所暗示，`ChatPromptTemplate` 非常适合用来创建聊天模型需要的提示词，即基于角色的对话交互。\n",
    "\n",
    "在这个 notebook 的后半部分，我们将学习如何利用我们对聊天模型交互中各种角色的理解。但首先，让我们重温一些熟悉的任务，同时注意提示词和聊天模型的响应是如何被构建以表明它们确实是角色对话的一部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47b0908",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c81567",
   "metadata": {},
   "source": [
    "## 人类消息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fb84ae",
   "metadata": {},
   "source": [
    "首先，我们将创建一个非常简单的聊天提示模板。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1783b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(\"{prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c51bf6",
   "metadata": {},
   "source": [
    "接下来，我们将通过调用提示模板来实例化一个实际的提示词，然后打印出完整的提示词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f2153",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.invoke({\"prompt\": \"hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44687456",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721eff27",
   "metadata": {},
   "source": [
    "首先注意到这个提示词是一个 `ChatPromptValue`：这是一个用于聊天模型的提示词。\n",
    "\n",
    "接下来，我们注意到消息被叫做 `HumanMessage`。在聊天对话中，消息总是与某种角色相关联，而这条消息被理解为是由“人类”角色生成的。\n",
    "\n",
    "调用提示词的 `to_messages` 方法能更清晰地看到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0dbc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb66ea0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85132264",
   "metadata": {},
   "source": [
    "## AI 消息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab44c331",
   "metadata": {},
   "source": [
    "让我们创建一个非常基本的链，以便我们可以将提示词发送给聊天模型，然后仔细查看它返回给我们的消息。值得注意的是，我们在链的末尾没有包含解析器，因为我们想要探索模型的整个响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9184c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1128eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"prompt\": \"hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2469f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083123f",
   "metadata": {},
   "source": [
    "模型的响应是一个 `AIMessage`，我们（以及模型）可以理解为这个消息是由“AI”角色生成的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eac725f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d098d5d8",
   "metadata": {},
   "source": [
    "## 在提示词中明确使用角色"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b14ba",
   "metadata": {},
   "source": [
    "在 LangChain 的底层，`ChatPromptTemplate` 一直在管理“人类”提示词和“AI”聊天模型响应的角色。不过，LangChain 也提供了简单易用的机制来进行明确的角色管理。\n",
    "\n",
    "最简单的方法是用 `ChatPromptTemplate.from_messages`，它接受一个消息列表，其中每条消息是一个二元组，第一个值表示与消息相关联的角色，第二个值是消息的内容。\n",
    "\n",
    "我们来用 `ChatPromptTemplate.from_messages` 重新创建之前 `from_template` 创建的完全相同的提示词。这次我们明确声明提示将与“人类”角色相关联。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426a8109",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{prompt}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646ca73",
   "metadata": {},
   "source": [
    "可以看到，就像之前做的那样，提示是一个 `ChatPromptValue`，其中包含一个 `HumanMessage` 类型的消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dfbff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.invoke({\"prompt\": \"hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca264003",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c23fc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79efb5b",
   "metadata": {},
   "source": [
    "我们可以像使用 `from_template` 创建的提示词那样使用这个提示模板。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d727ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d5c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"prompt\": \"hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec250f84",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30dd2f5",
   "metadata": {},
   "source": [
    "## 直接使用 ChatPromptMessages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b101c1",
   "metadata": {},
   "source": [
    "顺便提一下，在 LangChain 的最新版本中，我们可以直接使用 `ChatPromptMessages`，这相当于使用 `ChatPromptTemplate.from_messages`。因此下面这两种写法是等价的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a90046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{prompt}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0926aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatPromptTemplate([\n",
    "    (\"human\", \"{prompt}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db5ff51",
   "metadata": {},
   "source": [
    "本课程中，我们主要用 `from_messages`，因为您在文档和文献中会更频繁地见到这种用法，不过您可以随意使用这两种方法中的任何一种。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eaf748",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b594ea06",
   "metadata": {},
   "source": [
    "## 练习：创建一个明确的人类消息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d2e6b4",
   "metadata": {},
   "source": [
    "作为一个非常简单的练习，为了让您主动使用人类消息，请重构以下链以使用 `ChatPromptTemplate.from_messages`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_template(\"Give the concise etomology of the following English word: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421365cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.invoke({\"word\": \"learning\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e079ba",
   "metadata": {},
   "source": [
    "### 您的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab32c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f259919",
   "metadata": {},
   "source": [
    "### 参考答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973dabb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Give the concise etomology of the following English word: {word}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41512ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33173678",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b213a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.invoke({\"word\": \"learning\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf70ba33",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52d2eff",
   "metadata": {},
   "source": [
    "## 明确使用 AI 角色"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f921345f",
   "metadata": {},
   "source": [
    "除了提供“人类”角色消息外，我们还可以将传递 AI 角色的消息给模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82504969",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Hello.\"),\n",
    "    (\"ai\", \"Hello, how are you?\"),\n",
    "    (\"human\", \"{prompt}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667e8b1e",
   "metadata": {},
   "source": [
    "如果我们调用这个提示，可以看到与我们之前发送给聊天模型的提示不同，它包含了 3 条消息，其中两条与人类角色相关，另一条与 AI 角色相关。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065f229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.invoke({\"prompt\": \"I'm well, thanks!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dc2b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a199a0d",
   "metadata": {},
   "source": [
    "这种能力使我们能够构建包含额外上下文的提示，以便模型在生成响应时使用。\n",
    "\n",
    "从模型的角度来看，它看到的是当前聊天对话中已经发生的内容，这些关于已经发生的上下文可以影响模型在后续对话轮次中的响应。\n",
    "\n",
    "有两种主要的利用这种能力的方式。\n",
    "\n",
    "第一种是当我们想要实现聊天机器人功能时。在每次人类与 AI 交互后，可以将这次交互添加到我们的提示词中。因此，每当我们向聊天机器人发送消息时，它都能了解到完整对话上下文，从而能更恰当地做出回应。稍后我们将详细探讨如何创建聊天机器人功能。\n",
    "\n",
    "第二种是构建我们自己虚构的人类与 AI 的交互，作为模型如何应对后续人类消息的示例。这种提供人类与 AI 交互示例的技术被称为少样本提示（few-shot prompting），我们将在下一个 notebook 中讨论这个话题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48330bc0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b545a1",
   "metadata": {},
   "source": [
    "## 使用 `HumanMessage` 和 `AIMessage`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f13272c",
   "metadata": {},
   "source": [
    "在 LangChain 中，通常有多种方式来完成同样的事，这在创建角色特定的消息时也适用。目前为止，我们一直在用二元组语法创建与角色明确相关的消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9168fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Hello.\"),\n",
    "    (\"ai\", \"Hello, how are you?\"),\n",
    "    (\"human\", \"{prompt}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b591569",
   "metadata": {},
   "source": [
    "实际上还可以用 LangChain 的 `HumanMessage` 和 `AIMessage` 类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b5f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4916a357",
   "metadata": {},
   "source": [
    "下面这种写法跟二元组实现是等价的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613bfc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    HumanMessage(content=\"Hello\"),\n",
    "    AIMessage(content=\"Hello, how are you?\"),\n",
    "    HumanMessage(content=\"{prompt}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91adbd0d",
   "metadata": {},
   "source": [
    "这真的只是一个选择问题，您可以在应用中选择任何一种写法，这个课程中也可以随意选择。重要的是能够识别和理解它们，因为您可能会在技术文档和示例中看到这两种。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4184087",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0d9559",
   "metadata": {},
   "source": [
    "现在您已经熟悉了人类和 AI 消息，包括如何在聊天提示模板中编写它们。下一个 notebook 您将学习一种强大且流行的技术，称为少样本提示，这将利用您的消息编写技能为聊天模型提供示例，从而影响它们的行为。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
